{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f5b1646",
   "metadata": {},
   "source": [
    "# Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69316ae5",
   "metadata": {},
   "source": [
    "A decision tree is a flowchart-like tree structure where an internal node represents feature(or attribute), the branch represents a decision rule, and each leaf node represents the outcome. The topmost node in a decision tree is known as the root node. It learns to partition on the basis of the attribute value. It partitions the tree in recursively manner call recursive partitioning. This flowchart-like structure helps you in decision making. It's visualization like a flowchart diagram which easily mimics the human level thinking. That is why decision trees are easy to understand and interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f4d8f2",
   "metadata": {},
   "source": [
    "![https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1545934190/1_r5ikdb.png](https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1545934190/1_r5ikdb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ca68a",
   "metadata": {},
   "source": [
    "Decision Tree is a white box type of ML algorithm. It shares internal decision-making logic, which is not available in the black box type of algorithms such as Neural Network. Its training time is faster compared to the neural network algorithm. The time complexity of decision trees is a function of the number of records and number of attributes in the given data. The decision tree is a distribution-free or non-parametric method, which does not depend upon probability distribution assumptions. Decision trees can handle high dimensional data with good accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a085b456",
   "metadata": {},
   "source": [
    "# How does the Decision Tree Algorithm Work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505a7ab4",
   "metadata": {},
   "source": [
    "The basic idea behind any decision tree algorithm is as follows:\n",
    "- Select the best attribute using Attribute Selection Measures(ASM) to split the records.\n",
    "- Make that attribute a decision node and breaks the dataset into smaller subsets.\n",
    "- Starts tree building by repeating this process recursively for each child until one of the condition will match:\n",
    "    - All the tuples belong to the same attribute value.\n",
    "    - There are no more remaining attributes.\n",
    "    - There are no more instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309d5a53",
   "metadata": {},
   "source": [
    "# Important terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab5ddda",
   "metadata": {},
   "source": [
    "- **Root Node**: This attribute is used for dividing the data into two or more sets. The feature attribute in this node is selected based on Attribute Selection Techniques.\n",
    "- **Branch or Sub-Tree**: A part of the entire decision tree is called a branch or sub-tree.\n",
    "- **Splitting**: Dividing a node into two or more sub-nodes based on if-else conditions.\n",
    "- **Decision Node**: After splitting the sub-nodes into further sub-nodes, then it is called the decision node.\n",
    "- **Leaf or Terminal Node**: This is the end of the decision tree where it cannot be split into further sub-nodes.\n",
    "- **Pruning**: Removing a sub-node from the tree is called pruning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94690542",
   "metadata": {},
   "source": [
    "# What is Attribute Selective Measure(ASM)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571bf427",
   "metadata": {},
   "source": [
    "Attribute Subset Selection Measure is a technique used in the data mining process for data reduction. The data reduction is necessary to make better analysis and prediction of the target variable.\n",
    "\n",
    "The two main ASM techniques are\n",
    "\n",
    "- Gini index\n",
    "- Information Gain(ID3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce7bbf3",
   "metadata": {},
   "source": [
    "## Gini index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17cad6f",
   "metadata": {},
   "source": [
    "The measure of the degree of probability of a particular variable being wrongly classified when it is randomly chosen is called the Gini index or Gini impurity. The data is equally distributed based on the Gini index.\n",
    "\n",
    "Mathematical Formula :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dff254",
   "metadata": {},
   "source": [
    "![https://cdn-images-1.medium.com/max/300/0*pE3uG1i28u5ClQVQ.png](https://cdn-images-1.medium.com/max/300/0*pE3uG1i28u5ClQVQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2481bb",
   "metadata": {},
   "source": [
    "Pi = probability of an object being classified into a particular class.\n",
    "\n",
    "When you use the Gini index as the criterion for the algorithm to select the feature for the root node.,The feature with the least Gini index is selected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaabe01",
   "metadata": {},
   "source": [
    "## Information Gain(ID3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd468398",
   "metadata": {},
   "source": [
    "Entropy is the main concept of this algorithm, which helps determine a feature or attribute that gives maximum information about a class is called Information gain or ID3 algorithm. By using this method, we can reduce the level of entropy from the root node to the leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cdf2d0",
   "metadata": {},
   "source": [
    "Mathematical Formula :\n",
    "\n",
    "![https://cdn-images-1.medium.com/max/264/0*REu9I7JF09rPT5FD.png](https://cdn-images-1.medium.com/max/264/0*REu9I7JF09rPT5FD.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bce3e5b",
   "metadata": {},
   "source": [
    "‘p’, denotes the probability of E(S), which denotes the entropy. The feature or attribute with the highest ID3 gain is used as the root for the splitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c644a9cd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "605f9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "955cb37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('madfhantr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1061752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c998167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d51a6ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['Gender','Married','Education','Self_Employed','Credit_History','Loan_Status']]\n",
    "\n",
    "train['Gender']=train['Gender'].replace(to_replace='Male',value='1')\n",
    "train['Gender']=train['Gender'].replace(to_replace='Female',value='0')\n",
    "\n",
    "\n",
    "train['Married']=train['Married'].replace(to_replace='Yes',value='1')\n",
    "train['Married']=train['Married'].replace(to_replace='No',value='0')\n",
    "\n",
    "\n",
    "train['Self_Employed']=train['Self_Employed'].replace(to_replace='No',value='0')\n",
    "train['Self_Employed']=train['Self_Employed'].replace(to_replace='Yes',value='1')\n",
    "\n",
    "\n",
    "train['Education']=train['Education'].replace(to_replace='Graduate',value='1')\n",
    "train['Education']=train['Education'].replace(to_replace='Not Graduate',value='0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36d1c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['Loan_Status'])\n",
    "y = train.Loan_Status\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e13f0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982bc731",
   "metadata": {},
   "source": [
    "Before we visualize the tree, let us do some calculations and find out the root node by using Entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70096703",
   "metadata": {},
   "source": [
    "### **Calculation 1:** Find the Entropy of the total dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95257f0",
   "metadata": {},
   "source": [
    "![https://cdn-images-1.medium.com/proxy/0*iEYUSmQpG3JdnHzM.png](https://cdn-images-1.medium.com/proxy/0*iEYUSmQpG3JdnHzM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc691d15",
   "metadata": {},
   "source": [
    "- p = no of positive cases(Loan_Status accepted)\n",
    "- n = number of negative cases(Loan_Status not accepted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2776de",
   "metadata": {},
   "source": [
    "In the data set, we have\n",
    "\n",
    "p = 332 , n=148, p+n=480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1056e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 332\n",
    "n = 148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d278e44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8912402011913028"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-p/(p+n)*math.log2(p/(p+n)) - n/(p+n)*math.log2(n/(p+n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85121431",
   "metadata": {},
   "source": [
    "### **Calculation 2:** Now find the Entropy and gain for every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14a79148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    394\n",
       "0     86\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35bac6e",
   "metadata": {},
   "source": [
    "#### **Gender**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fc43df",
   "metadata": {},
   "source": [
    "There are two types in this male(1) and female(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171f8def",
   "metadata": {},
   "source": [
    "**Condition 1:** Male\n",
    "\n",
    "data-set with all male’s in it and then,\n",
    "\n",
    "p = 278, n=116 , p+n=394\n",
    "\n",
    "Entropy(G=Male) = 0.87"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569b2712",
   "metadata": {},
   "source": [
    "**Condition 2:** Female\n",
    "\n",
    "data-set with all female’s in it and then,\n",
    "\n",
    "p = 54 , n = 32 , p+n = 86\n",
    "\n",
    "Entropy(G=Female) = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7e2b4e",
   "metadata": {},
   "source": [
    "**Average Information in Gender column is**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feabbaa7",
   "metadata": {},
   "source": [
    "![https://cdn-images-1.medium.com/max/868/0*iqh79gPraxvz-TFN.png](https://cdn-images-1.medium.com/max/868/0*iqh79gPraxvz-TFN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6645d3",
   "metadata": {},
   "source": [
    "I(Gender) = (Entropy(G = Male) * p+n/480) + (Entropy(G = Female) * p+n/480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2250c3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8843333333333332"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.87*(278+116)/480) + (0.95*(54+32)/480)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b3fbb0",
   "metadata": {},
   "source": [
    "![https://cdn-images-1.medium.com/max/1024/0*xDCyd_1ffDcO7PBT.png](https://cdn-images-1.medium.com/max/1024/0*xDCyd_1ffDcO7PBT.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0adcc54",
   "metadata": {},
   "source": [
    "Gain = 0.89 – 0.88\n",
    "\n",
    "Gain = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b4ed7c",
   "metadata": {},
   "source": [
    "![https://cdn-images-1.medium.com/max/286/0*f2MyHJDrVbYWMQqw.png](https://cdn-images-1.medium.com/max/286/0*f2MyHJDrVbYWMQqw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1132dc88",
   "metadata": {},
   "source": [
    "Credit Score has the highest gain so that will be used in the root node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a788d5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"885pt\" height=\"433pt\"\n",
       " viewBox=\"0.00 0.00 884.50 433.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-429 880.5,-429 880.5,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#92c9f1\" stroke=\"black\" d=\"M495.5,-425C495.5,-425 361.5,-425 361.5,-425 355.5,-425 349.5,-419 349.5,-413 349.5,-413 349.5,-354 349.5,-354 349.5,-348 355.5,-342 361.5,-342 361.5,-342 495.5,-342 495.5,-342 501.5,-342 507.5,-348 507.5,-354 507.5,-354 507.5,-413 507.5,-413 507.5,-419 501.5,-425 495.5,-425\"/>\n",
       "<text text-anchor=\"start\" x=\"357.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Credit_History ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"371\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.893</text>\n",
       "<text text-anchor=\"start\" x=\"375.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 336</text>\n",
       "<text text-anchor=\"start\" x=\"362\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [104, 232]</text>\n",
       "<text text-anchor=\"start\" x=\"391\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = No</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e99356\" stroke=\"black\" d=\"M413.5,-306C413.5,-306 275.5,-306 275.5,-306 269.5,-306 263.5,-300 263.5,-294 263.5,-294 263.5,-235 263.5,-235 263.5,-229 269.5,-223 275.5,-223 275.5,-223 413.5,-223 413.5,-223 419.5,-223 425.5,-229 425.5,-235 425.5,-235 425.5,-294 425.5,-294 425.5,-300 419.5,-306 413.5,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"271.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Self_Employed ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"291.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.55</text>\n",
       "<text text-anchor=\"start\" x=\"296\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 55</text>\n",
       "<text text-anchor=\"start\" x=\"291.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [48, 7]</text>\n",
       "<text text-anchor=\"start\" x=\"305\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Yes</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M399.36,-341.91C392.97,-333.01 386.15,-323.51 379.56,-314.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"382.27,-312.1 373.59,-306.02 376.58,-316.19 382.27,-312.1\"/>\n",
       "<text text-anchor=\"middle\" x=\"369.54\" y=\"-326.99\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#6ab5eb\" stroke=\"black\" d=\"M571.5,-306C571.5,-306 455.5,-306 455.5,-306 449.5,-306 443.5,-300 443.5,-294 443.5,-294 443.5,-235 443.5,-235 443.5,-229 449.5,-223 455.5,-223 455.5,-223 571.5,-223 571.5,-223 577.5,-223 583.5,-229 583.5,-235 583.5,-235 583.5,-294 583.5,-294 583.5,-300 577.5,-306 571.5,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"465\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Married ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"456\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.721</text>\n",
       "<text text-anchor=\"start\" x=\"460.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 281</text>\n",
       "<text text-anchor=\"start\" x=\"451.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [56, 225]</text>\n",
       "<text text-anchor=\"start\" x=\"476\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = No</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>0&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M457.99,-341.91C464.45,-333.01 471.36,-323.51 478.02,-314.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"481.02,-316.17 484.06,-306.02 475.35,-312.05 481.02,-316.17\"/>\n",
       "<text text-anchor=\"middle\" x=\"487.97\" y=\"-327.01\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#ea995e\" stroke=\"black\" d=\"M259,-187C259,-187 152,-187 152,-187 146,-187 140,-181 140,-175 140,-175 140,-116 140,-116 140,-110 146,-104 152,-104 152,-104 259,-104 259,-104 265,-104 271,-110 271,-116 271,-116 271,-175 271,-175 271,-181 265,-187 259,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"149\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Education ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"148\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.632</text>\n",
       "<text text-anchor=\"start\" x=\"157\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 44</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [37, 7]</text>\n",
       "<text text-anchor=\"start\" x=\"166\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Yes</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M296.27,-222.91C285.06,-213.47 273.03,-203.34 261.51,-193.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"263.54,-190.78 253.64,-187.02 259.04,-196.14 263.54,-190.78\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M399.5,-179.5C399.5,-179.5 301.5,-179.5 301.5,-179.5 295.5,-179.5 289.5,-173.5 289.5,-167.5 289.5,-167.5 289.5,-123.5 289.5,-123.5 289.5,-117.5 295.5,-111.5 301.5,-111.5 301.5,-111.5 399.5,-111.5 399.5,-111.5 405.5,-111.5 411.5,-117.5 411.5,-123.5 411.5,-123.5 411.5,-167.5 411.5,-167.5 411.5,-173.5 405.5,-179.5 399.5,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"302\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"302\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n",
       "<text text-anchor=\"start\" x=\"297.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [11, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"311\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Yes</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M346.58,-222.91C347.13,-212.2 347.72,-200.62 348.28,-189.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"351.78,-189.83 348.8,-179.67 344.79,-189.47 351.78,-189.83\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#e88f4f\" stroke=\"black\" d=\"M119,-68C119,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 119,0 119,0 125,0 131,-6 131,-12 131,-12 131,-56 131,-56 131,-62 125,-68 119,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.469</text>\n",
       "<text text-anchor=\"start\" x=\"17\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n",
       "<text text-anchor=\"start\" x=\"17\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"26\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Yes</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M153.37,-103.73C141.24,-94.24 128.35,-84.16 116.28,-74.72\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"118.11,-71.7 108.07,-68.3 113.8,-77.22 118.11,-71.7\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#eb9c63\" stroke=\"black\" d=\"M268,-68C268,-68 161,-68 161,-68 155,-68 149,-62 149,-56 149,-56 149,-12 149,-12 149,-6 155,0 161,0 161,0 268,0 268,0 274,0 280,-6 280,-12 280,-12 280,-56 280,-56 280,-62 274,-68 268,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"157\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.672</text>\n",
       "<text text-anchor=\"start\" x=\"166\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 34</text>\n",
       "<text text-anchor=\"start\" x=\"161.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [28, 6]</text>\n",
       "<text text-anchor=\"start\" x=\"175\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Yes</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M208.85,-103.73C209.53,-95.43 210.25,-86.67 210.94,-78.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"214.43,-78.55 211.76,-68.3 207.46,-77.98 214.43,-78.55\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<path fill=\"#7cbeee\" stroke=\"black\" d=\"M561,-187C561,-187 454,-187 454,-187 448,-187 442,-181 442,-175 442,-175 442,-116 442,-116 442,-110 448,-104 454,-104 454,-104 561,-104 561,-104 567,-104 573,-110 573,-116 573,-116 573,-175 573,-175 573,-181 567,-187 561,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"460\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Gender ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"450\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.815</text>\n",
       "<text text-anchor=\"start\" x=\"454.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 103</text>\n",
       "<text text-anchor=\"start\" x=\"450\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [26, 77]</text>\n",
       "<text text-anchor=\"start\" x=\"470\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = No</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M511.42,-222.91C510.99,-214.56 510.53,-205.67 510.09,-197.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"513.59,-196.83 509.58,-187.02 506.59,-197.19 513.59,-196.83\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<path fill=\"#61b1ea\" stroke=\"black\" d=\"M719.5,-187C719.5,-187 603.5,-187 603.5,-187 597.5,-187 591.5,-181 591.5,-175 591.5,-175 591.5,-116 591.5,-116 591.5,-110 597.5,-104 603.5,-104 603.5,-104 719.5,-104 719.5,-104 725.5,-104 731.5,-110 731.5,-116 731.5,-116 731.5,-175 731.5,-175 731.5,-181 725.5,-187 719.5,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"605\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Education ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"604\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.654</text>\n",
       "<text text-anchor=\"start\" x=\"608.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 178</text>\n",
       "<text text-anchor=\"start\" x=\"599.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [30, 148]</text>\n",
       "<text text-anchor=\"start\" x=\"624\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = No</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>6&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M564.85,-222.91C576.9,-213.38 589.84,-203.15 602.21,-193.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"604.57,-195.97 610.24,-187.02 600.23,-190.48 604.57,-195.97\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<path fill=\"#91c9f1\" stroke=\"black\" d=\"M417,-68C417,-68 310,-68 310,-68 304,-68 298,-62 298,-56 298,-56 298,-12 298,-12 298,-6 304,0 310,0 310,0 417,0 417,0 423,0 429,-6 429,-12 429,-12 429,-56 429,-56 429,-62 423,-68 417,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"310.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.89</text>\n",
       "<text text-anchor=\"start\" x=\"315\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 39</text>\n",
       "<text text-anchor=\"start\" x=\"306\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [12, 27]</text>\n",
       "<text text-anchor=\"start\" x=\"326\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = No</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M453.88,-103.73C441.29,-94.15 427.89,-83.96 415.37,-74.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"417.37,-71.57 407.29,-68.3 413.13,-77.14 417.37,-71.57\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<path fill=\"#70b8ec\" stroke=\"black\" d=\"M566,-68C566,-68 459,-68 459,-68 453,-68 447,-62 447,-56 447,-56 447,-12 447,-12 447,-6 453,0 459,0 459,0 566,0 566,0 572,0 578,-6 578,-12 578,-12 578,-56 578,-56 578,-62 572,-68 566,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"455\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.758</text>\n",
       "<text text-anchor=\"start\" x=\"464\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 64</text>\n",
       "<text text-anchor=\"start\" x=\"455\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [14, 50]</text>\n",
       "<text text-anchor=\"start\" x=\"475\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = No</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>7&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M509.36,-103.73C509.74,-95.52 510.13,-86.86 510.51,-78.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"514.02,-78.45 510.98,-68.3 507.03,-78.13 514.02,-78.45\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<path fill=\"#6fb8ec\" stroke=\"black\" d=\"M706.5,-68C706.5,-68 608.5,-68 608.5,-68 602.5,-68 596.5,-62 596.5,-56 596.5,-56 596.5,-12 596.5,-12 596.5,-6 602.5,0 608.5,0 608.5,0 706.5,0 706.5,0 712.5,0 718.5,-6 718.5,-12 718.5,-12 718.5,-56 718.5,-56 718.5,-62 712.5,-68 706.5,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"604.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.75</text>\n",
       "<text text-anchor=\"start\" x=\"609\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 28</text>\n",
       "<text text-anchor=\"start\" x=\"604.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 22]</text>\n",
       "<text text-anchor=\"start\" x=\"620\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = No</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>10&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M660.01,-103.73C659.71,-95.52 659.39,-86.86 659.09,-78.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"662.58,-78.17 658.72,-68.3 655.58,-78.42 662.58,-78.17\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<path fill=\"#5fb0ea\" stroke=\"black\" d=\"M864.5,-68C864.5,-68 748.5,-68 748.5,-68 742.5,-68 736.5,-62 736.5,-56 736.5,-56 736.5,-12 736.5,-12 736.5,-6 742.5,0 748.5,0 748.5,0 864.5,0 864.5,0 870.5,0 876.5,-6 876.5,-12 876.5,-12 876.5,-56 876.5,-56 876.5,-62 870.5,-68 864.5,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"749\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.634</text>\n",
       "<text text-anchor=\"start\" x=\"753.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 150</text>\n",
       "<text text-anchor=\"start\" x=\"744.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [24, 126]</text>\n",
       "<text text-anchor=\"start\" x=\"769\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = No</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>10&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M715.49,-103.73C728.17,-94.15 741.67,-83.96 754.27,-74.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"756.53,-77.12 762.4,-68.3 752.32,-71.53 756.53,-77.12\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x7f0edc13a8c0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz \n",
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                               feature_names=['Gender','Married','Education','Self_Employed','Credit_History'],\n",
    "                               class_names=['Yes','No'],filled=True,\n",
    "                                rounded=True,  \n",
    "                              special_characters=True) \n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"Entropy\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a742749e",
   "metadata": {},
   "source": [
    "Well, it’s like we got the calculations right!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "27120f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7986111111111112"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2746de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00989198, 0.02781814, 0.00829242, 0.03330419, 0.92069327])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c988e3",
   "metadata": {},
   "source": [
    "## Assumptions made while creating the decision tree:\n",
    "- While starting the training, the whole data-set is considered as the root.\n",
    "- The input values are preferred to be categorical.\n",
    "- Records are distributed based on attribute values.\n",
    "- The attributes are placed as the root node of the tree is based on statistical results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a896ced2",
   "metadata": {},
   "source": [
    "## Optimizing Decision Tree Performance\n",
    "- criterion : optional (default=”gini”) or Choose attribute selection measure: This parameter allows us to use the different-different attribute selection measure. Supported criteria are “gini” for the Gini index and “entropy” for the information gain.\n",
    "- splitter : string, optional (default=”best”) or Split Strategy: This parameter allows us to choose the split strategy. Supported strategies are “best” to choose the best split and “random” to choose the best random split.\n",
    "- max_depth : int or None, optional (default=None) or Maximum Depth of a Tree: The maximum depth of the tree. If None, then nodes are expanded until all the leaves contain less than min_samples_split samples. The higher value of maximum depth causes overfitting, and a lower value causes underfitting (Source)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e613b135",
   "metadata": {},
   "source": [
    "## Pros\n",
    "- Decision trees are easy to interpret and visualize.\n",
    "- It can easily capture Non-linear patterns.\n",
    "- It requires fewer data preprocessing from the user, for example, there is no need to normalize columns.\n",
    "- It can be used for feature engineering such as predicting missing values, suitable for variable selection.\n",
    "- The decision tree has no assumptions about distribution because of the non-parametric nature of the algorithm. (Source)\n",
    "\n",
    "## Cons\n",
    "- Sensitive to noisy data. It can overfit noisy data.\n",
    "- The small variation(or variance) in data can result in the different decision tree. This can be reduced by bagging and boosting algorithms.\n",
    "- Decision trees are biased with imbalance dataset, so it is recommended that balance out the dataset before creating the decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b690ce02",
   "metadata": {},
   "source": [
    "https://www.freecodecamp.org/news/how-to-use-the-tree-based-algorithm-for-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c03d05d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
