{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1f8ae64",
   "metadata": {},
   "source": [
    "# 1. What is Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1c78bb",
   "metadata": {},
   "source": [
    "In 1959, Arthur Samuel, a computer scientist who pioneered the study of artificial intelligence, described machine learning as “the study that gives computers the ability to learn without being explicitly programmed.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cb9d63",
   "metadata": {},
   "source": [
    "Machine Learning is an application of artificial intelligence where a computer/machine learns from the past experiences (input data) and makes future predictions. The performance of such a system should be at least human level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8539e0be",
   "metadata": {},
   "source": [
    "![https://machinelearningmastery.com/wp-content/uploads/2015/12/Traditional-Programming-vs-Machine-Learning-300x213.png](https://machinelearningmastery.com/wp-content/uploads/2015/12/Traditional-Programming-vs-Machine-Learning-300x213.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4249e6",
   "metadata": {},
   "source": [
    "# 2. Applications of Machine Learning\n",
    "\n",
    "Sample applications of machine learning:\n",
    "\n",
    "- Web search: ranking page based on what you are most likely to click on.\n",
    "- Computational biology: rational design drugs in the computer based on past experiments.\n",
    "- Finance: decide who to send what credit card offers to. Evaluation of risk on credit offers. How to decide where to invest money.\n",
    "- E-commerce:  Predicting customer churn. Whether or not a transaction is fraudulent.\n",
    "- Space exploration: space probes and radio astronomy.\n",
    "- Robotics: how to handle uncertainty in new environments. Autonomous. Self-driving car.\n",
    "- Information extraction: Ask questions over databases across the web.\n",
    "- Social networks: Data on relationships and preferences. Machine learning to extract value from data.\n",
    "- Debugging: Use in computer science problems like debugging. Labor intensive process. Could suggest where the bug could be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a024573",
   "metadata": {},
   "source": [
    "# 3. Machine Learning Categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfe91c6",
   "metadata": {},
   "source": [
    "Machine Learning is generally categorized into three types: Supervised Learning, Unsupervised Learning, Reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426fceb3",
   "metadata": {},
   "source": [
    "## Supervised Learning:\n",
    "In supervised learning the machine experiences the examples along with the labels or targets for each example. The labels in the data help the algorithm to correlate the features.\n",
    "\n",
    "Two of the most common supervised machine learning tasks are classification and regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3d5502",
   "metadata": {},
   "source": [
    "- In **classification** problems the machine must learn to predict discrete values. That is, the machine must predict the most probable category, class, or label for new examples. Applications of classification include predicting whether a stock's price will rise or fall, or deciding if a news article belongs to the politics or leisure section. \n",
    "- In **regression** problems the machine must predict the value of a continuous response variable. Examples of regression problems include predicting the sales for a new product, or the salary for a job based on its description."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a25440b",
   "metadata": {},
   "source": [
    "## Unsupervised Learning:\n",
    "When we have unclassified and unlabeled data, the system attempts to uncover patterns from the data . There is no label or target given for the examples. One common task is to group similar examples together called clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9106487",
   "metadata": {},
   "source": [
    "## Semi-supervised learning:\n",
    "Semi-supervised learning is an approach to machine learning that combines a small amount of labeled data with a large amount of unlabeled data during training. Semi-supervised learning falls between unsupervised learning (with no labeled training data) and supervised learning (with only labeled training data). It is a special instance of weak supervision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dc05da",
   "metadata": {},
   "source": [
    "## Reinforcement Learning:\n",
    "Reinforcement learning refers to goal-oriented algorithms, which learn how to attain a complex objective (goal) or maximize along a particular dimension over many steps. This method allows machines and software agents to automatically determine the ideal behavior within a specific context in order to maximize its performance. Simple reward feedback is required for the agent to learn which action is best; this is known as the reinforcement signal. For example, maximize the points won in a game over many moves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4ab443",
   "metadata": {},
   "source": [
    "# 4. A Framework For Studying supervised Learning\n",
    "\n",
    "Terminology used in machine learning:\n",
    "\n",
    "- **Training example:** a sample from x including its output from the target function\n",
    "- **Target function:** the mapping function f from x to f(x)\n",
    "- **Hypothesis:** approximation of f, a candidate function.\n",
    "- **Concept:** A boolean target function, positive examples and negative examples for the 1/0 class values.\n",
    "- **Classifier:** Learning program outputs a classifier that can be used to classify.\n",
    "- **Learner:** Process that creates the classifier.\n",
    "- **Hypothesis space:** set of possible approximations of f that the algorithm can create.\n",
    "- **Version space:** subset of the hypothesis space that is consistent with the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964d6c28",
   "metadata": {},
   "source": [
    "# 5. Commonly used Machine Learning Algorithms\n",
    "- Linear Regression\n",
    "- Logistic Regression\n",
    "- K Nearest Neighbour (KNN)\n",
    "- K-Means Clustering\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Support Vector Machines (SVM)\n",
    "- Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a5aab6",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2a0f6c",
   "metadata": {},
   "source": [
    "Here’s some info about Linear Regression, It is an approach to form a relation between one or more explanatory variables in a linear fashion. Those variables may be dependent or independent. Multiple Linear Regression is used to make predictions based on multiple variables. It assumes a linear relationship between input variable (x) and the output variable (y), Where this y is formed by the linear combination of the input variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e29d3e",
   "metadata": {},
   "source": [
    "The equation for linear regression is y = b0+b1*x , Where b0,b1 are changed to adjust the line to get the best possible prediction in order to minimize loss.\n",
    "As we know that y=mx+c is the equation of a line with slope “m” and intercept “c”. Here slope is the weights and intercept is the bias. So the actual equation can be written as y=wx+b."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136a8678",
   "metadata": {},
   "source": [
    "![https://miro.medium.com/max/720/0*wB_oQO7aqtCUWu3p.png](https://miro.medium.com/max/720/0*wB_oQO7aqtCUWu3p.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cf05eb",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9e5662",
   "metadata": {},
   "source": [
    "- Logistic regression is one of the most popular Machine Learning algorithms, which comes under the Supervised Learning technique. It is used for predicting the categorical dependent variable using a given set of independent variables.\n",
    "- Logistic regression predicts the output of a categorical dependent variable. Therefore the outcome must be a categorical or discrete value. It can be either Yes or No, 0 or 1, true or False, etc. but instead of giving the exact value as 0 and 1, it gives the probabilistic values which lie between 0 and 1.\n",
    "- Logistic Regression is much similar to the Linear Regression except that how they are used. Linear Regression is used for solving Regression problems, whereas Logistic regression is used for solving the classification problems.\n",
    "- In Logistic regression, instead of fitting a regression line, we fit an \"S\" shaped logistic function, which predicts two maximum values (0 or 1). \n",
    "- 1 / (1 + e^-value)\n",
    "- The curve from the logistic function indicates the likelihood of something such as whether the cells are cancerous or not, a mouse is obese or not based on its weight, etc.\n",
    "- Logistic Regression is a significant machine learning algorithm because it has the ability to provide probabilities and classify new data using continuous and discrete datasets.\n",
    "- Logistic Regression can be used to classify the observations using different types of data and can easily determine the most effective variables used for the classification. The below image is showing the logistic function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d697b4",
   "metadata": {},
   "source": [
    "![https://static.javatpoint.com/tutorial/machine-learning/images/logistic-regression-in-machine-learning.png](https://static.javatpoint.com/tutorial/machine-learning/images/logistic-regression-in-machine-learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2160e17a",
   "metadata": {},
   "source": [
    "## KNN\n",
    "- K-Nearest Neighbour is one of the simplest Machine Learning algorithms based on Supervised Learning technique.\n",
    "- K-NN algorithm assumes the similarity between the new case/data and available cases and put the new case into the category that is most similar to the available categories.\n",
    "- K-NN algorithm stores all the available data and classifies a new data point based on the similarity. This means when new data appears then it can be easily classified into a well suite category by using K- NN algorithm.\n",
    "- K-NN algorithm can be used for Regression as well as for Classification but mostly it is used for the Classification problems.\n",
    "- K-NN is a non-parametric algorithm, which means it does not make any assumption on underlying data.\n",
    "- It is also called a lazy learner algorithm because it does not learn from the training set immediately instead it stores the dataset and at the time of classification, it performs an action on the dataset.\n",
    "- KNN algorithm at the training phase just stores the dataset and when it gets new data, then it classifies that data into a category that is much similar to the new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec79c72",
   "metadata": {},
   "source": [
    "![https://static.javatpoint.com/tutorial/machine-learning/images/k-nearest-neighbor-algorithm-for-machine-learning2.png](https://static.javatpoint.com/tutorial/machine-learning/images/k-nearest-neighbor-algorithm-for-machine-learning2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c51eac",
   "metadata": {},
   "source": [
    "## K-Means Clustring\n",
    "K-Means Clustering is an Unsupervised Learning algorithm, which groups the unlabeled dataset into different clusters. Here K defines the number of pre-defined clusters that need to be created in the process, as if K=2, there will be two clusters, and for K=3, there will be three clusters, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12f2c5",
   "metadata": {},
   "source": [
    "The k-means clustering algorithm mainly performs two tasks:\n",
    "\n",
    "- Determines the best value for K center points or centroids by an iterative process.\n",
    "- Assigns each data point to its closest k-center. Those data points which are near to the particular k-center, create a cluster.\n",
    "Hence each cluster has datapoints with some commonalities, and it is away from other clusters.\n",
    "\n",
    "The below diagram explains the working of the K-means Clustering Algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c024444c",
   "metadata": {},
   "source": [
    "![https://static.javatpoint.com/tutorial/machine-learning/images/k-means-clustering-algorithm-in-machine-learning.png](https://static.javatpoint.com/tutorial/machine-learning/images/k-means-clustering-algorithm-in-machine-learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642d4077",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "- Decision Tree is a Supervised learning technique that can be used for both classification and Regression problems, but mostly it is preferred for solving Classification problems. It is a tree-structured classifier, where internal nodes represent the features of a dataset, branches represent the decision rules and each leaf node represents the outcome.\n",
    "- In a Decision tree, there are two nodes, which are the Decision Node and Leaf Node. Decision nodes are used to make any decision and have multiple branches, whereas Leaf nodes are the output of those decisions and do not contain any further branches.\n",
    "- The decisions or the test are performed on the basis of features of the given dataset.\n",
    "- It is a graphical representation for getting all the possible solutions to a problem/decision based on given conditions.\n",
    "- It is called a decision tree because, similar to a tree, it starts with the root node, which expands on further branches and constructs a tree-like structure.\n",
    "- In order to build a tree, we use the CART algorithm, which stands for Classification and Regression Tree algorithm.\n",
    "- A decision tree simply asks a question, and based on the answer (Yes/No), it further split the tree into subtrees.\n",
    "- Below diagram explains the general structure of a decision tree:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fadca20",
   "metadata": {},
   "source": [
    "![https://static.javatpoint.com/tutorial/machine-learning/images/decision-tree-classification-algorithm.png](https://static.javatpoint.com/tutorial/machine-learning/images/decision-tree-classification-algorithm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a31176b",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "Random Forest is a popular machine learning algorithm that belongs to the supervised learning technique. It can be used for both Classification and Regression problems in ML. It is based on the concept of ensemble learning, which is a process of combining multiple classifiers to solve a complex problem and to improve the performance of the model.\n",
    "\n",
    "As the name suggests, \"Random Forest is a classifier that contains a number of decision trees on various subsets of the given dataset and takes the average to improve the predictive accuracy of that dataset.\" Instead of relying on one decision tree, the random forest takes the prediction from each tree and based on the majority votes of predictions, and it predicts the final output.\n",
    "\n",
    "The greater number of trees in the forest leads to higher accuracy and prevents the problem of overfitting.\n",
    "\n",
    "The below diagram explains the working of the Random Forest algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131d9fd1",
   "metadata": {},
   "source": [
    "![https://static.javatpoint.com/tutorial/machine-learning/images/random-forest-algorithm.png](https://static.javatpoint.com/tutorial/machine-learning/images/random-forest-algorithm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb207402",
   "metadata": {},
   "source": [
    "## SVM\n",
    "Support Vector Machine or SVM is one of the most popular Supervised Learning algorithms, which is used for Classification as well as Regression problems. However, primarily, it is used for Classification problems in Machine Learning.\n",
    "\n",
    "The goal of the SVM algorithm is to create the best line or decision boundary that can segregate n-dimensional space into classes so that we can easily put the new data point in the correct category in the future. This best decision boundary is called a hyperplane.\n",
    "\n",
    "SVM chooses the extreme points/vectors that help in creating the hyperplane. These extreme cases are called as support vectors, and hence algorithm is termed as Support Vector Machine. Consider the below diagram in which there are two different categories that are classified using a decision boundary or hyperplane:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a98776",
   "metadata": {},
   "source": [
    "![https://static.javatpoint.com/tutorial/machine-learning/images/support-vector-machine-algorithm.png](https://static.javatpoint.com/tutorial/machine-learning/images/support-vector-machine-algorithm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66225228",
   "metadata": {},
   "source": [
    "## Naïve Bayes\n",
    "- Naïve Bayes algorithm is a supervised learning algorithm, which is based on Bayes theorem and used for solving classification problems.\n",
    "- It is mainly used in text classification that includes a high-dimensional training dataset.\n",
    "- Naïve Bayes Classifier is one of the simple and most effective Classification algorithms which helps in building the fast machine learning models that can make quick predictions.\n",
    "- It is a probabilistic classifier, which means it predicts on the basis of the probability of an object.\n",
    "- Some popular examples of Naïve Bayes Algorithm are spam filtration, Sentimental analysis, and classifying articles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da46958",
   "metadata": {},
   "source": [
    "The Naïve Bayes algorithm is comprised of two words Naïve and Bayes, Which can be described as:\n",
    "\n",
    "- **Naïve:** It is called Naïve because it assumes that the occurrence of a certain feature is independent of the occurrence of other features. Such as if the fruit is identified on the bases of color, shape, and taste, then red, spherical, and sweet fruit is recognized as an apple. Hence each feature individually contributes to identify that it is an apple without depending on each other.\n",
    "- **Bayes:** It is called Bayes because it depends on the principle of Bayes' Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a2b29f",
   "metadata": {},
   "source": [
    "![https://static.javatpoint.com/tutorial/machine-learning/images/naive-bayes-classifier-algorithm.png](https://static.javatpoint.com/tutorial/machine-learning/images/naive-bayes-classifier-algorithm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6798fce2",
   "metadata": {},
   "source": [
    "# 6. Train Test Spliting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132685f8",
   "metadata": {},
   "source": [
    "The train-test split procedure is used to estimate the performance of machine learning algorithms when they are used to make predictions on data not used to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014e5e85",
   "metadata": {},
   "source": [
    "It can be used for classification or regression problems and can be used for any supervised learning algorithm.\n",
    "\n",
    "The procedure involves taking a dataset and dividing it into two subsets. The first subset is used to fit the model and is referred to as the training dataset. The second subset is not used to train the model; instead, the input element of the dataset is provided to the model, then predictions are made and compared to the expected values. This second dataset is referred to as the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb88616",
   "metadata": {},
   "source": [
    "- **Train Dataset:** Used to fit the machine learning model.\n",
    "- **Test Dataset:** Used to evaluate the fit machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249bf816",
   "metadata": {},
   "source": [
    "**The train-test procedure is appropriate when there is a sufficiently large dataset available.**\n",
    "\n",
    "Large enough to suitable representations of the problem domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8f93a8",
   "metadata": {},
   "source": [
    "A suitable representation of the problem domain means that there are enough records to cover all common cases and most uncommon cases in the domain. This might mean combinations of input variables observed in practice. It might require thousands, hundreds of thousands, or millions of examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8806a88b",
   "metadata": {},
   "source": [
    "**In addition to dataset size, another reason to use the train-test split evaluation procedure is computational efficiency.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d853450d",
   "metadata": {},
   "source": [
    "The procedure has one main configuration parameter, which is the size of the train and test sets. This is most commonly expressed as a percentage between 0 and 1 for either the train or test datasets. For example, a training set with the size of 0.67 (67 percent) means that the remainder percentage 0.33 (33 percent) is assigned to the test set.\n",
    "\n",
    "There is no optimal split percentage.\n",
    "\n",
    "You must choose a split percentage that meets your project’s objectives with considerations that include:\n",
    "\n",
    "- Computational cost in training the model.\n",
    "- Computational cost in evaluating the model.\n",
    "- Training set representativeness.\n",
    "- Test set representativeness.\n",
    "\n",
    "Nevertheless, common split percentages include:\n",
    "\n",
    "- Train: 80%, Test: 20%\n",
    "- Train: 70%, Test: 30%\n",
    "- Train: 67%, Test: 33%\n",
    "- Train: 50%, Test: 50%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15bdd1d",
   "metadata": {},
   "source": [
    "## Train-Test Split Procedure in Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efebc0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65bbb3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ABNB_NYC_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ba5852f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48895"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e616b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['id', 'name', 'host_id', 'host_name', 'neighbourhood_group',\n",
    "       'neighbourhood', 'latitude', 'longitude', 'room_type',\n",
    "       'minimum_nights', 'number_of_reviews', 'last_review',\n",
    "       'reviews_per_month', 'calculated_host_listings_count',\n",
    "       'availability_365']].values\n",
    "y = data['price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f38a81e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48895, 15), (48895,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f98cd2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55572d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5010368, 'Upper East Side Gem!', 25840204, 'Daniel', 'Manhattan',\n",
       "       'Upper East Side', 40.77546, -73.95165, 'Entire home/apt', 3, 75,\n",
       "       '2019-04-27', 1.44, 1, 234], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "06add68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39116, 15), (39116,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f1522a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9779, 15), (9779,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fb6c39",
   "metadata": {},
   "source": [
    "## Repeatable Train-Test Splits\n",
    "Another important consideration is that rows are assigned to the train and test sets randomly.\n",
    "\n",
    "This is done to ensure that datasets are a representative sample (e.g. random sample) of the original dataset, which in turn, should be a representative sample of observations from the problem domain.\n",
    "\n",
    "When comparing machine learning algorithms, it is desirable (perhaps required) that they are fit and evaluated on the same subsets of the dataset.\n",
    "\n",
    "This can be achieved by fixing the seed for the pseudo-random number generator used when splitting the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9167ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32015007, 'Cozy room next to subway!', 240033083, 'Patrik',\n",
       "       'Manhattan', 'Harlem', 40.82272, -73.95478, 'Private room', 2, 0,\n",
       "       nan, nan, 1, 0], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b9c878b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "67fad554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25674366, 'Mid Century Modern Williamsburg Condo', 9038810,\n",
       "       'Sanjay', 'Brooklyn', 'Williamsburg', 40.71577, -73.9553,\n",
       "       'Entire home/apt', 3, 11, '2019-05-16', 0.87, 1, 1], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cd7307",
   "metadata": {},
   "source": [
    "# Cross Validation using K-folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512c3615",
   "metadata": {},
   "source": [
    "Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8e2059",
   "metadata": {},
   "source": [
    "![https://www.researchgate.net/profile/Fabian-Pedregosa/publication/278826818/figure/fig10/AS:614336141750297@1523480558954/The-technique-of-KFold-cross-validation-illustrated-here-for-the-case-K-4-involves.png](https://www.researchgate.net/profile/Fabian-Pedregosa/publication/278826818/figure/fig10/AS:614336141750297@1523480558954/The-technique-of-KFold-cross-validation-illustrated-here-for-the-case-K-4-involves.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a193216",
   "metadata": {},
   "source": [
    "![https://scikit-learn.org/stable/_images/grid_search_cross_validation.png](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f99f21c",
   "metadata": {},
   "source": [
    "The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=10 becoming 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a1062",
   "metadata": {},
   "source": [
    "It is a popular method because it is simple to understand and because it generally results in a less biased or less optimistic estimate of the model skill than other methods, such as a simple train/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9276a948",
   "metadata": {},
   "source": [
    "The general procedure is as follows:\n",
    "\n",
    "1. Shuffle the dataset randomly.\n",
    "2. Split the dataset into k groups\n",
    "3. For each unique group:\n",
    "    1. Take the group as a hold out or test data set\n",
    "    2. Take the remaining groups as a training data set\n",
    "    3. Fit a model on the training set and evaluate it on the test set\n",
    "    4. Retain the evaluation score and discard the model\n",
    "4. Summarize the skill of the model using the sample of model evaluation scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c9047d",
   "metadata": {},
   "source": [
    "Importantly, each observation in the data sample is assigned to an individual group and stays in that group for the duration of the procedure. This means that each sample is given the opportunity to be used in the hold out set 1 time and used to train the model k-1 times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa71fe95",
   "metadata": {},
   "source": [
    "## Configuration of k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1448140",
   "metadata": {},
   "source": [
    "The k value must be chosen carefully for your data sample.\n",
    "\n",
    "A poorly chosen value for k may result in a mis-representative idea of the skill of the model, such as a score with a high variance (that may change a lot based on the data used to fit the model), or a high bias, (such as an overestimate of the skill of the model).\n",
    "\n",
    "Three common tactics for choosing a value for k are as follows:\n",
    "\n",
    "- Representative: The value for k is chosen such that each train/test group of data samples is large enough to be statistically representative of the broader dataset.\n",
    "- k=10: The value for k is fixed to 10, a value that has been found through experimentation to generally result in a model skill estimate with low bias a modest variance.\n",
    "- k=n: The value for k is fixed to n, where n is the size of the dataset to give each test sample an opportunity to be used in the hold out dataset. This approach is called leave-one-out cross-validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c85ec5",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1b7cf581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e0a2581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ABNB_NYC_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "77f422ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "90fce997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4890  4891  4892 ... 48892 48893 48894] [   0    1    2 ... 4887 4888 4889]\n",
      "(44005, 16) (4890, 16)\n",
      "\n",
      "\n",
      "[    0     1     2 ... 48892 48893 48894] [4890 4891 4892 ... 9777 9778 9779]\n",
      "(44005, 16) (4890, 16)\n",
      "\n",
      "\n",
      "[    0     1     2 ... 48892 48893 48894] [ 9780  9781  9782 ... 14667 14668 14669]\n",
      "(44005, 16) (4890, 16)\n",
      "\n",
      "\n",
      "[    0     1     2 ... 48892 48893 48894] [14670 14671 14672 ... 19557 19558 19559]\n",
      "(44005, 16) (4890, 16)\n",
      "\n",
      "\n",
      "[    0     1     2 ... 48892 48893 48894] [19560 19561 19562 ... 24447 24448 24449]\n",
      "(44005, 16) (4890, 16)\n",
      "\n",
      "\n",
      "[    0     1     2 ... 48892 48893 48894] [24450 24451 24452 ... 29336 29337 29338]\n",
      "(44006, 16) (4889, 16)\n",
      "\n",
      "\n",
      "[    0     1     2 ... 48892 48893 48894] [29339 29340 29341 ... 34225 34226 34227]\n",
      "(44006, 16) (4889, 16)\n",
      "\n",
      "\n",
      "[    0     1     2 ... 48892 48893 48894] [34228 34229 34230 ... 39114 39115 39116]\n",
      "(44006, 16) (4889, 16)\n",
      "\n",
      "\n",
      "[    0     1     2 ... 48892 48893 48894] [39117 39118 39119 ... 44003 44004 44005]\n",
      "(44006, 16) (4889, 16)\n",
      "\n",
      "\n",
      "[    0     1     2 ... 44003 44004 44005] [44006 44007 44008 ... 48892 48893 48894]\n",
      "(44006, 16) (4889, 16)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train, test in kf.split(data):\n",
    "    train_data = data.iloc[train]\n",
    "    test_data = data.iloc[test]\n",
    "    print(train, test)\n",
    "    print(train_data.shape, test_data.shape)\n",
    "    # train model here\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5cf983",
   "metadata": {},
   "source": [
    "# Overfitting vs Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8017dd21",
   "metadata": {},
   "source": [
    "Understanding model fit is important for understanding the root cause for poor model accuracy. This understanding will guide you to take corrective steps. We can determine whether a predictive model is underfitting or overfitting the training data by looking at the prediction error on the training data and the evaluation data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5da7dab",
   "metadata": {},
   "source": [
    "![https://docs.aws.amazon.com/machine-learning/latest/dg/images/mlconcepts_image5.png](https://docs.aws.amazon.com/machine-learning/latest/dg/images/mlconcepts_image5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0036ebe9",
   "metadata": {},
   "source": [
    "Your model is **underfitting** the training data when the model performs poorly on the training data. This is because the model is unable to capture the relationship between the input examples (often called X) and the target values (often called Y)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b0e6d0",
   "metadata": {},
   "source": [
    "Your model is **overfitting** your training data when you see that the model performs well on the training data but does not perform well on the evaluation data. This is because the model is memorizing the data it has seen and is unable to generalize to unseen examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676ddc69",
   "metadata": {},
   "source": [
    "Poor performance on the training data could be because the model is too simple (the input features are not expressive enough) to describe the target well. Performance can be improved by increasing model flexibility. To increase model flexibility, try the following:\n",
    "\n",
    "- Add new domain-specific features and more feature Cartesian products, and change the types of feature processing used (e.g., increasing n-grams size)\n",
    "\n",
    "- Decrease the amount of regularization used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2317d4f0",
   "metadata": {},
   "source": [
    "If your model is overfitting the training data, it makes sense to take actions that reduce model flexibility. To reduce model flexibility, try the following:\n",
    "\n",
    "- Feature selection: consider using fewer feature combinations, decrease n-grams size, and decrease the number of numeric attribute bins.\n",
    "\n",
    "- Increase the amount of regularization used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4671e5",
   "metadata": {},
   "source": [
    "Accuracy on training and test data could be poor because the learning algorithm did not have enough data to learn from. You could improve performance by doing the following:\n",
    "\n",
    "- Increase the amount of training data examples.\n",
    "\n",
    "- Increase the number of passes on the existing training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c5f412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
